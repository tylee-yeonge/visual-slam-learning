# Week 3: SVD (특이값 분해) 집중

## 📌 개요

**SVD (Singular Value Decomposition, 특이값 분해)** 는 Visual SLAM에서 가장 빈번하게 사용되는 행렬 분해 기법입니다. Essential Matrix에서 카메라 포즈(R, t)를 추출하거나, Homography 분해, PnP 문제 해결 등 거의 모든 기하학적 문제에서 SVD가 등장합니다.

이번 주에는 SVD의 **기하학적 직관**을 얻고, 실제 코드로 구현해보며 SLAM에서의 활용을 이해합니다.

---

## 🎯 학습 목표

1. SVD의 기하학적 의미 이해 (회전 → 스케일 → 회전)
2. 특이값(Singular Value)의 의미 파악
3. SVD를 이용한 최소자승 해 구하기
4. NumPy로 SVD 분해 실습
5. SLAM에서 SVD가 사용되는 핵심 장면 이해

---

## 📚 사전 지식

- Week 1-2에서 학습한 선형대수 기본 개념
- 행렬 곱셈, 역행렬, 고유값 분해
- Python NumPy 기본 사용법

---

## ⏱️ 예상 학습 시간

| 항목 | 시간 |
|------|------|
| 이론 학습 | 2-3시간 |
| 실습 예제 | 2-3시간 |
| SLAM 응용 이해 | 1-2시간 |
| **총 소요시간** | **5-8시간** |

---

# 📖 Part 1: SVD 기초 이론

## 1.1 왜 SVD가 필요한가?

### 고유값 분해의 한계

**고유값 분해(Eigenvalue Decomposition)** 는 **정방 행렬(n×n)** 에만 적용됩니다.

```python
# 고유값 분해
A = V Λ V⁻¹  # A는 반드시 정방 행렬!
```

### 현실의 문제: 직사각 행렬

현실에서는 **직사각 행렬(m×n)** 이 더 많습니다:
- 이미지: 480×640 (행≠열)
- 8개의 대응점으로 Essential Matrix 구할 때: 8×9 행렬
- 센서 데이터: 측정 횟수 × 변수 개수 (대부분 다름)

> [!IMPORTANT]
> **SVD는 어떤 크기의 행렬이든 분해할 수 있는 "만능 도구"입니다!**

---

## 1.2 SVD 정의

### 📌 핵심 공식

임의의 m×n 행렬 A는 다음과 같이 분해됩니다:

```
A = U Σ Vᵀ
```

### 각 행렬의 의미

| 행렬 | 크기 | 성질 | 의미 |
|------|------|------|------|
| **U** | m×m | 직교 행렬 | "출력 공간의 좌표축" |
| **Σ** | m×n | 대각 행렬 | "각 축으로 얼마나 늘리기/줄이기" |
| **Vᵀ** | n×n | 직교 행렬 | "입력 공간의 좌표축" |

### 간단한 예제

```python
import numpy as np

# 3×2 직사각 행렬
A = np.array([
    [3, 2],
    [2, 3],
    [2, -2]
])

U, S, Vt = np.linalg.svd(A, full_matrices=True)

print(f"A 크기: {A.shape}")      # (3, 2)
print(f"U 크기: {U.shape}")      # (3, 3)
print(f"S (특이값): {S}")        # [5.0, 3.0]
print(f"Vᵀ 크기: {Vt.shape}")    # (2, 2)
```

---

## 1.3 기하학적 의미: 회전-스케일-회전

SVD의 핵심 직관은 **모든 선형 변환은 세 단계로 분해된다**는 것입니다:

```
      Vᵀ          Σ           U
[입력] → [회전] → [스케일] → [회전] → [출력]
```

### 비유: 포토샵 변환

```
원본 이미지 → [회전] → [늘리기/줄이기] → [또 회전] → 결과 이미지
```

### 계산 순서 이해

벡터 x에 A를 적용:
```
y = A × x = (U × Σ × Vᵀ) × x
```

행렬 곱셈은 **오른쪽에서 왼쪽으로** 계산:
```
(U × Σ × Vᵀ) × x = U × (Σ × (Vᵀ × x))
                    ↑     ↑      ↑
                  3단계  2단계   1단계 (먼저!)
```

**실제 변환 순서:**
1. **Vᵀ × x**: 입력을 특이 방향으로 회전
2. **Σ × (결과)**: 각 축 방향으로 스케일링
3. **U × (결과)**: 출력 방향으로 회전

---

## 1.4 `full_matrices` 파라미터

행렬 A가 **m×n** 크기일 때 (k = min(m, n)):

| `full_matrices` | U 크기 | S 크기 | Vᵀ 크기 | 용도 |
|-----------------|--------|--------|---------|------|
| `True` (기본값) | m×m | k | n×n | Null space 분석, 완전한 직교 기저 필요 시 |
| `False` | m×k | k | k×n | 메모리/계산 효율, 대부분의 실용적 사용 |

**SLAM에서의 선택:**
- **Homography/Essential Matrix 분해** → `True` (Null space 벡터 필요)
- **최소자승 해, 이미지 압축** → `False` (효율성)

---

## 1.5 특이값(Singular Value)의 의미

### 특이값이란?

특이값은 **Σ 행렬의 대각선 원소**입니다:

```
Σ = [σ₁  0   0 ]
    [0   σ₂  0 ]
    [0   0   σ₃]
```

- **σ₁ ≥ σ₂ ≥ ... ≥ σᵣ ≥ 0**: 항상 **양수**이고 **내림차순**
- **랭크(rank)**: 0이 아닌 특이값의 개수

### 특이값의 의미

| 특이값 | 의미 | 비유 |
|--------|------|------|
| **σ₁ (가장 큼)** | 가장 중요한 정보 방향 | "메인 스토리" |
| **σ₂** | 두 번째로 중요한 방향 | "서브 스토리" |
| **σₖ ≈ 0** | 거의 무시해도 되는 정보 | "노이즈" |
| **σ = 0** | 그 방향 정보 완전히 없음 | "빈 공간" |

---

## 1.6 특이값을 손으로 계산하는 방법

### 📐 계산 공식

> [!IMPORTANT]
> **왜 A^T A를 사용하는가?**
>
> m×n 직사각 행렬 A는 **직접 고유값을 구할 수 없습니다!** (고유값은 정방 행렬에만 정의됨)
>
> 따라서 A를 정방 행렬로 변환:
> - **A^T A**: n×n 정방 행렬 (일반적으로 사용)
> - **A A^T**: m×m 정방 행렬

**계산 단계:**

1. **A^T A 계산** (결과는 n×n 대칭 행렬)
2. **고유값(λ) 구하기**: det(A^T A - λI) = 0
3. **특이값(σ) 계산**: σᵢ = √λᵢ

### 손계산 예제: 2×2 행렬

행렬 **A = [[3, 0], [4, 5]]** 의 특이값:

**1단계: A^T A 계산**
```
A^T = [[3, 4],
       [0, 5]]

A^T A = [[3, 4],  × [[3, 0],  = [[25, 20],
         [0, 5]]     [4, 5]]     [20, 25]]
```

**2단계: 특성방정식**
```
det(A^T A - λI) = 0
(25-λ)² - 400 = 0
λ² - 50λ + 225 = 0

λ = (50 ± 40) / 2
λ₁ = 45, λ₂ = 5
```

**3단계: 특이값**
```
σ₁ = √45 = 3√5 ≈ 6.708
σ₂ = √5 ≈ 2.236
```

---

# 📊 Part 2: SVD의 핵심 개념

## 2.1 랭크(Rank) 계산

### 수학적 원리

> [!IMPORTANT]
> **핵심 정리**: 행렬의 랭크 = 0이 아닌 특이값의 개수

### 왜 `np.sum(s > 1e-10)`으로 계산하는가?

**문제: 수치 오차(Numerical Error)**

컴퓨터는 부동소수점 연산에서 완벽한 0을 만들지 못합니다:

```python
# 이론적으로 특이값이 0이어야 하는 행렬
A = np.array([[1, 2], [2, 4]])  # 랭크 1

_, s, _ = np.linalg.svd(A)
print(s[1])  # 3.7747582837255322e-16 ← 완벽한 0이 아님!
```

**해결책: 허용 오차(Tolerance) 사용**

```python
# ❌ 잘못된 방법
rank = np.sum(s == 0)  # 수치 오차 때문에 작동 안 함!

# ✅ 올바른 방법
tolerance = 1e-10
rank = np.sum(s > tolerance)
```

### 허용 오차 값 선택

| 허용 오차 | 용도 | 설명 |
|----------|------|------|
| `1e-10` | **일반적 사용** ✅ | 대부분의 경우에 적합 |
| `1e-15` | 고정밀 계산 | 매우 정확한 데이터일 때 |
| `1e-6` | 노이즈가 많은 데이터 | 센서 데이터, 실험 측정 |

### 코드 동작 원리

```python
s = np.array([5.477, 0.365, 0.0000000001])

# 1단계: 불린 배열 생성
boolean_array = s > 1e-10  # [True, True, False]

# 2단계: np.sum()이 True를 1로, False를 0으로 변환하여 합산
rank = np.sum(boolean_array)  # 2
```

---

## 2.2 조건수(Condition Number)

### 📐 정의

**조건수(Condition Number)** 는 행렬의 **수치적 안정성**을 나타냅니다:

```
κ(A) = σ_max / σ_min = (가장 큰 특이값) / (가장 작은 특이값)
```

### 🤔 왜 중요한가?

조건수는 **"입력의 작은 변화가 출력을 얼마나 크게 바꾸는가?"** 를 측정합니다.

**비유:**
```
조건수가 작은 행렬 (κ ≈ 1~100):
    넓고 튼튼한 다리 → 안전

조건수가 큰 행렬 (κ > 1000):
    좁고 흔들리는 다리 → 위험

조건수가 매우 큰 행렬 (κ → ∞):
    거의 끊어진 다리 → 특이 행렬
```

### 수학적 의미

선형 시스템 **Ax = b**를 풀 때:

```
입력(b)의 상대 오차: δb / ||b||
   ↓
출력(x)의 상대 오차: ≤ κ(A) × (δb / ||b||)
   ↑
입력 오차가 최대 κ(A)배만큼 증폭됨!
```

**예시:**
```python
# 조건수 = 1000인 행렬
# 입력(b)에 0.1% 오차 → 출력(x)에 최대 100% 오차 가능!
κ = 1000
input_error = 0.001  # 0.1%
max_output_error = κ * input_error  # 1.0 = 100%
```

### 조건수로 행렬 분류

| 조건수 범위 | 분류 | 대처 방법 |
|------------|------|----------|
| **κ ≈ 1** | 완벽한 조건 (직교 행렬) | 문제 없음 ✅ |
| **κ < 100** | 안정 | 일반 알고리즘 사용 |
| **κ < 1,000** | 약간 불안정 | 정규화 고려 |
| **κ < 10⁶** | 불안정 (ill-conditioned) | 정규화 필수 ⚠️ |
| **κ > 10⁶** | 거의 특이 | 다른 방법 사용 🚨 |

### NumPy 계산 방법

```python
# 방법 1: SVD 사용 (권장)
U, s, Vt = np.linalg.svd(A)
cond = s[0] / s[-1]

# 방법 2: NumPy 내장 함수
cond = np.linalg.cond(A)
```

---

# 🔧 Part 3: SVD의 핵심 응용

## 3.1 동차 시스템(Homogeneous System) 풀기

### 📐 동차 시스템이란?

**동차 시스템**은 우변이 **0인 선형 방정식 시스템**입니다:

```
Ax = 0
```

여기서:
- A: m×n 행렬
- x: n×1 벡터 (미지수)
- 0: m×1 영벡터

### 비동차 시스템과의 차이

```python
# 동차 시스템 (Homogeneous)
Ax = 0  # 우변이 0

# 비동차 시스템 (Non-homogeneous)
Ax = b  # 우변이 0이 아님
```

### 동차 시스템의 특징

#### 1. 항상 해가 존재

```python
# 최소한 자명해(Trivial Solution)가 항상 존재
x = 0  # 영벡터

A @ 0 = 0  # 항상 성립! ✅
```

#### 2. 해의 구조

```python
# 동차 시스템의 해는 벡터 공간을 이룸

# 만약 x₁, x₂가 해라면
A @ x₁ = 0
A @ x₂ = 0

# 그들의 선형결합도 해!
A @ (c₁x₁ + c₂x₂) = 0 ✅
```

#### 3. 해의 종류

| 경우 | 조건 | 해의 개수 |
|------|------|----------|
| **자명해만** | rank(A) = n | 1개 (x = 0) |
| **비자명해 존재** | rank(A) < n | 무수히 많음 |

### Null Space (영공간)와의 관계

**Null Space(영공간)** = 동차 시스템 Ax = 0의 모든 해의 집합

```python
Null(A) = { x | Ax = 0 }

# 영공간의 차원
dim(Null(A)) = n - rank(A)
```

### SVD로 동차 시스템 푸는 방법

```python
# 동차 시스템: Ax = 0

# 1단계: SVD 분해
U, S, Vt = np.linalg.svd(A)

# 2단계: 최소 특이값에 대응하는 벡터 = 해
x = Vt[-1, :]  # V의 마지막 행

# 3단계: 검증
result = A @ x
print(f"Ax ≈ 0? {np.allclose(result, 0)}")
```

### 왜 Vt[-1]이 해인가?

```python
# SVD: A = U Σ Vᵀ
# Ax = 0이면
# U Σ Vᵀ x = 0
# Σ Vᵀ x = 0  (U는 가역)

# 만약 σₙ ≈ 0이면
# Vᵀ x의 n번째 성분만 크고 나머지 작아야 함
# → x는 V의 n번째 열 방향! ✅
```

### SLAM 예시: Essential Matrix 계산

```python
# 에피폴라 제약: pᵀ₂ E p₁ = 0
# E의 9개 원소를 벡터 e로 나열

# 각 대응점마다 하나의 방정식
A = []
for (p1, p2) in point_pairs:
    x1, y1 = p1
    x2, y2 = p2
    # [x₂x₁, x₂y₁, x₂, y₂x₁, y₂y₁, y₂, x₁, y₁, 1] @ e = 0
    A.append([x2*x1, x2*y1, x2, y2*x1, y2*y1, y2, x1, y1, 1])

A = np.array(A)

# 8개 대응점 → 8×9 동차 시스템
# SVD로 해 구하기
U, S, Vt = np.linalg.svd(A)
e = Vt[-1, :]  # 최소 특이값에 대응하는 벡터
E = e.reshape(3, 3)
```

---

## 3.2 최소자승 해(Least Squares Solution)

### 📐 문제 정의

**과결정 시스템(Overdetermined System)** 은 방정식의 개수가 미지수보다 많은 경우입니다:

```
Ax = b
(m×n) × (n×1) = (m×1)
여기서 m > n (방정식 개수 > 미지수 개수)
```

이 경우 **정확한 해가 존재하지 않는 경우가 대부분**이므로, **잔차(residual)를 최소화**하는 해를 찾습니다.

### 🎯 잔차(Residual)란?

**잔차 = 실제값 - 예측값**

```
residual = y - ŷ
```

#### 직관적 예시

```python
# 데이터 포인트
x = [1, 2, 3, 4]
y = [2.1, 2.9, 4.2, 4.8]  # 실제 관측값

# 최소자승으로 구한 직선: ŷ = 1.05 + 0.9x
y_pred = [1.95, 2.85, 3.75, 4.65]  # 예측값

# 잔차 계산
residuals = y - y_pred
          = [0.15, 0.05, 0.45, 0.15]
```

#### 잔차의 의미

```python
# 양수 잔차: 예측이 실제보다 작음 (under-prediction)
residual = 2.9 - 2.85 = +0.05  # 실제가 더 큼

# 음수 잔차: 예측이 실제보다 큼 (over-prediction)
residual = 2.0 - 2.15 = -0.15  # 예측이 더 큼

# 0에 가까울수록: 좋은 예측!
residual ≈ 0  # 완벽한 예측
```

#### 잔차 기반 성능 지표

```python
residuals = np.array([0.15, 0.05, 0.45, 0.15])

# 잔차 제곱합 (RSS: Residual Sum of Squares)
rss = np.sum(residuals**2)  # 0.235

# 평균 제곱근 오차 (RMSE)
rmse = np.sqrt(np.mean(residuals**2))  # 0.243

# 평균 절대 오차 (MAE)
mae = np.mean(np.abs(residuals))  # 0.200
```

### 최소자승법의 목표

다음을 최소화하는 x를 찾는 것:

```
minimize ||Ax - b||² = Σ(residual_i)²
```

### 💡 직관적 예시: 직선 피팅

```python
# 데이터: (1, 2.1), (2, 2.9), (3, 4.2), (4, 4.8)
# 목표: y = a + bx 형태의 직선 찾기

A = np.array([
    [1, 1],   # y₁ = a + b·1
    [1, 2],   # y₂ = a + b·2
    [1, 3],   # y₃ = a + b·3
    [1, 4]    # y₄ = a + b·4
])
b = np.array([2.1, 2.9, 4.2, 4.8])

# 4개 방정식, 2개 미지수 → 과결정 시스템
# 모든 점을 정확히 지나는 직선은 없음!
```

### ✨ SVD를 이용한 해법

**1단계: SVD 분해**
```
A = U Σ Vᵀ
```

**2단계: 유사역행렬(Pseudoinverse) 계산**
```
A⁺ = V Σ⁺ Uᵀ
```
여기서 Σ⁺는 각 σᵢ를 1/σᵢ로 바꾼 것 (σᵢ ≈ 0이면 0 유지)

**3단계: 최소자승 해**
```
x = A⁺b = V Σ⁺ Uᵀ b
```

### 💻 구현 예제

```python
import numpy as np

# 직선 피팅 문제
A = np.array([[1, 1], [1, 2], [1, 3], [1, 4]])
b = np.array([2.1, 2.9, 4.2, 4.8])

# 방법 1: NumPy 최소자승 (내부적으로 SVD 사용)
x_lstsq, residuals, _, _ = np.linalg.lstsq(A, b, rcond=None)
print(f"해: a = {x_lstsq[0]:.4f}, b = {x_lstsq[1]:.4f}")

# 방법 2: SVD로 직접 계산
U, S, Vt = np.linalg.svd(A, full_matrices=False)
S_inv = np.diag(1 / S)  # 특이값의 역수로 대각 행렬 생성
A_pinv = Vt.T @ S_inv @ U.T
x_svd = A_pinv @ b

# 예측과 잔차
y_pred = A @ x_lstsq
residual = b - y_pred
print(f"잔차: {residual}")
print(f"잔차 제곱합: {np.sum(residual**2):.6f}")
```

### 📊 정규방정식 vs SVD

| | 정규방정식 (AᵀA)⁻¹Aᵀb | SVD A⁺b |
|---|---|---|
| **수치 안정성** | 조건수 제곱 (불안정) ⚠️ | 안정적 ✅ |
| **랭크 부족** | 역행렬 없음 ❌ | 유사역행렬 사용 ✅ |
| **작은 특이값** | 큰 오차 증폭 | 자동 제거 가능 |

### 🤖 SLAM에서의 활용

- **평면 피팅**: 3D 점들로부터 평면 방정식 추정
- **카메라 캘리브레이션**: DLT로 투영 행렬 계산
- **ICP**: 두 점군 정합에서 최적 R, t 찾기
- **Bundle Adjustment**: 카메라 포즈와 3D 점 동시 최적화

> [!TIP]
> SLAM에서는 거의 항상 **SVD 기반 최소자승**을 사용합니다. 노이즈가 많고 조건수가 나쁜 경우가 많기 때문입니다!

---

## 3.3 저랭크 근사 (Low-Rank Approximation)

노이즈 제거 및 압축에 사용:

```python
# 상위 k개 특이값만 사용하여 행렬 근사
A_approx = U[:, :k] @ np.diag(S[:k]) @ Vt[:k, :]
```

---

# 🤖 Part 4: SLAM 핵심 응용

## 4.1 Essential Matrix (기본 행렬)

### 개념

**Essential Matrix (E)** 는 두 카메라 사이의 **상대적인 회전(R)과 평행이동(t)** 을 인코딩한 3×3 행렬입니다.

```
두 이미지에서 대응점 p₁, p₂가 있을 때:
p₂ᵀ · E · p₁ = 0  (Epipolar Constraint)
```

### 기하학적 의미

```
          에피폴라 평면
         /          \
        /            \
   카메라1 -------- 카메라2
       \    3D 점    /
        \     P     /
         \   /\   /
          \ /  \ /
          p₁    p₂
       (이미지1) (이미지2)
```

- 3D 점 P와 두 카메라 중심을 잇는 **에피폴라 평면**
- p₂는 반드시 **에피폴라 라인** 위에 있어야 함
- E는 이 기하학적 제약을 수학적으로 표현

### E의 성질

| 성질 | 설명 |
|------|------|
| 랭크 = 2 | 세 번째 특이값이 0 |
| 특이값 | [σ, σ, 0] 형태 (두 개가 동일) |
| 자유도 | 5 DOF (3 회전 + 2 방향, 스케일 불가) |

### SVD로 R, t 추출

```python
def decompose_essential_matrix(E):
    """Essential Matrix에서 R, t 추출"""
    U, S, Vt = np.linalg.svd(E)

    # W 행렬 (90도 회전)
    W = np.array([
        [0, -1, 0],
        [1, 0, 0],
        [0, 0, 1]
    ])

    # 4가지 가능한 해
    R1 = U @ W @ Vt
    R2 = U @ W.T @ Vt
    t1 = U[:, 2]
    t2 = -U[:, 2]

    # det(R) = 1 보장
    if np.linalg.det(R1) < 0:
        R1 = -R1
    if np.linalg.det(R2) < 0:
        R2 = -R2

    return [(R1, t1), (R1, t2), (R2, t1), (R2, t2)]
```

> [!IMPORTANT]
> **Cheirality Check**: 4개의 (R, t) 후보 중 **3D 점이 두 카메라 앞에 있는** 경우만 유효합니다.

---

## 4.2 Homography (호모그래피)

### 개념

**Homography (H)** 는 **동일 평면 위의 점들** 또는 **순수 회전** 일 때, 두 이미지 간의 변환을 나타내는 3×3 행렬입니다.

```
동차 좌표로: p₂ ~ H · p₁
(~는 스케일 불변 동치)
```

### 기하학적 의미

```
        평면 (π)
       +--------+
      /|       /|
     / |      / |
    +--+-----+  |
    | 3D 점들 | |
    |  (동일  | /
    |  평면)  |/
    +---------+
       ↓ ↓
  이미지1  이미지2
```

- 평면 위의 점들만 고려할 때 성립
- 예: 바닥, 벽, 포스터 등 평면 물체

### Homography 적용 사례

| 상황 | 설명 |
|------|------|
| 평면 물체 | 바닥면, 벽면의 특징점 매칭 |
| 순수 회전 | 카메라가 제자리에서만 회전 |
| 이미지 정합 | 파노라마 스티칭 |
| AR 마커 | 평면 마커 포즈 추정 |

### DLT로 H 계산

```python
def compute_homography_dlt(pts1, pts2):
    """DLT 알고리즘으로 Homography 계산"""
    A = []
    for (x1, y1), (x2, y2) in zip(pts1, pts2):
        A.append([-x1, -y1, -1, 0, 0, 0, x2*x1, x2*y1, x2])
        A.append([0, 0, 0, -x1, -y1, -1, y2*x1, y2*y1, y2])
    A = np.array(A)

    # SVD로 null space 찾기
    U, S, Vt = np.linalg.svd(A)
    H = Vt[-1].reshape(3, 3)

    # 정규화
    H = H / H[2, 2]

    return H
```

---

## 4.3 PnP (Perspective-n-Point)

### 개념

**PnP**는 **n개의 3D-2D 대응점**이 주어졌을 때, **카메라 포즈(R, t)를 추정**하는 문제입니다.

```
입력: 3D 점 {Pᵢ} (월드 좌표계), 2D 점 {pᵢ} (이미지)
출력: 카메라 포즈 [R | t]
```

### 기하학적 의미

```
        월드 좌표계
           P₁ ●
              \
               \  ← 3D 점들의 위치를 알고 있음
                \
    P₂ ●---------+-------- P₃ ●
                 |
                 | ← 어디서 촬영했을까?
                 |
              [카메라]
                 ↓
             이미지 (p₁, p₂, p₃)
```

### PnP 문제의 종류

| 최소 점 수 | 알고리즘 | 특징 |
|-----------|----------|------|
| 3점 (P3P) | P3P | 최소 해, 최대 4개 해 |
| 4점 (P4P) | 다양 | EPnP, DLT 등 |
| n점 | EPnP, DLT | 과결정 시스템, 최소자승 |

### OpenCV에서 PnP

```python
import cv2

# solvePnP: 반복적 최적화
success, rvec, tvec = cv2.solvePnP(
    pts_3d, pts_2d, K, dist_coeffs,
    flags=cv2.SOLVEPNP_ITERATIVE
)

# solvePnPRansac: RANSAC으로 아웃라이어 제거
success, rvec, tvec, inliers = cv2.solvePnPRansac(
    pts_3d, pts_2d, K, dist_coeffs
)
```

---

## 4.4 Triangulation (삼각측량)

### 개념

**Triangulation**은 **두 개 이상의 카메라에서 관측된 2D 점**으로부터 **3D 점 위치를 복원**하는 문제입니다.

```
입력: 2D 점 p₁, p₂ + 카메라 행렬 P₁, P₂
출력: 3D 점 X
```

### 기하학적 의미

```
          3D 점 X ● (알고 싶은 것)
                / \
               /   \
           광선1    광선2
             /       \
            /         \
       카메라1      카메라2
          ↓           ↓
         p₁           p₂
      (관측)        (관측)
```

- 이상적으로 두 광선이 3D 점에서 교차
- 실제로는 **노이즈로 인해 교차하지 않음**
- → 최소자승 해로 근사

### Linear Triangulation (DLT)

```python
def triangulate_dlt(p1, p2, P1, P2):
    """DLT 기반 Triangulation"""
    x1, y1 = p1
    x2, y2 = p2

    # A 행렬 구성
    A = np.array([
        x1 * P1[2] - P1[0],
        y1 * P1[2] - P1[1],
        x2 * P2[2] - P2[0],
        y2 * P2[2] - P2[1]
    ])

    # SVD로 AX = 0의 해 구하기
    U, S, Vt = np.linalg.svd(A)
    X = Vt[-1]  # 최소 특이값에 대응하는 벡터

    # 동차 좌표 → 유클리드 좌표
    X = X / X[3]

    return X[:3]
```

---

# 💻 실습 및 학습 자료

## 실습 파일

| 파일 | 내용 |
|------|------|
| `svd_basics.py` | SVD 기본 개념 및 기하학적 의미 실습 |
| `svd_quiz.py` | 주관식 퀴즈 (문제/답안 분리) |

## 실행 방법

```bash
cd "Studies/Phase 1/week3"
python3 svd_basics.py
python3 svd_quiz.py
```

---

## 🎬 추천 영상

| 영상 | 설명 |
|------|------|
| [3Blue1Brown - SVD](https://www.youtube.com/watch?v=vSczTbgc8Rc) | SVD 직관 이해 (필수!) |
| [Steve Brunton - SVD](https://www.youtube.com/watch?v=gXbThCXjZFM) | 공학적 관점에서의 SVD |
| [Cyrill Stachniss - Essential Matrix](https://www.youtube.com/watch?v=zX5NeY-GTO0) | SLAM에서 Essential Matrix |

---

# ✅ 학습 완료 체크리스트

- [ ] SVD의 기하학적 의미를 "회전-스케일-회전"으로 설명할 수 있다
- [ ] 특이값이 0인 것과 랭크의 관계를 설명할 수 있다
- [ ] 동차 시스템 Ax = 0을 SVD로 풀 수 있다
- [ ] 최소자승 해를 SVD로 구할 수 있다
- [ ] 잔차의 의미와 최소자승법의 관계를 이해한다
- [ ] NumPy로 SVD 분해를 수행하고 결과를 해석할 수 있다
- [ ] Essential Matrix에서 R, t 추출에 SVD가 왜 필요한지 이해한다

---

# 🔗 다음 단계

Week 3 완료 후 → **Week 4: 회전 표현**으로 이동
- 회전 행렬, 오일러 각, 쿼터니언 학습
- SVD가 회전 행렬 정규화에도 사용됨을 확인

---

# 📝 핵심 요약

## SVD 한 문장 요약

> **"어떤 행렬이든 '회전 → 스케일 → 회전'으로 분해할 수 있고, 특이값은 각 방향의 중요도를 알려준다."**

## 핵심 공식

```python
# SVD 분해
A = U Σ Vᵀ

# 동차 시스템 해
x = Vt[-1, :]  # Ax = 0의 해

# 최소자승 해
x = V @ Σ⁺ @ Uᵀ @ b  # Ax ≈ b의 해

# 잔차
residual = y - ŷ  # 실제 - 예측

# 랭크
rank = np.sum(S > 1e-10)

# 조건수
cond = S[0] / S[-1]
```

## SLAM 핵심 응용

1. **동차 시스템**: Essential Matrix, Homography 계산
2. **최소자승**: 평면 피팅, 캘리브레이션, ICP
3. **R, t 분해**: Essential Matrix에서 카메라 포즈 추출
4. **Triangulation**: 3D 점 복원
