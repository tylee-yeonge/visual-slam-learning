# Week 8: ë¹„ì„ í˜• ìµœì í™” (Nonlinear Optimization)

## ğŸ“Œ ê°œìš”

> ğŸ¯ **ëª©í‘œ**: ë°˜ë³µì  ìµœì í™”ë¡œ ë¹„ì„ í˜• ë¬¸ì œ í’€ê¸°
> â±ï¸ **ì˜ˆìƒ ì‹œê°„**: ì´ë¡  3ì‹œê°„ + ì‹¤ìŠµ 2ì‹œê°„

ì‹¤ì œ SLAM ë¬¸ì œëŠ” ëŒ€ë¶€ë¶„ **ë¹„ì„ í˜•**ì…ë‹ˆë‹¤. ì¹´ë©”ë¼ íˆ¬ì˜, íšŒì „ ì—°ì‚°, ì§€ìˆ˜ í•¨ìˆ˜ ë“±ì´ ëª¨ë‘ ë¹„ì„ í˜•ì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ë²ˆ ì£¼ì—ëŠ” **Gauss-Newton**, **Levenberg-Marquardt** ì•Œê³ ë¦¬ì¦˜ì„ ë°°ìš°ê³ , SLAM ì‹¤ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ **Ceres Solver**ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

### ğŸ¤” ì™œ ì´ê±¸ ë°°ì›Œì•¼ í• ê¹Œìš”?

**ì¼ìƒ ë¹„ìœ **: ì‚°ì—ì„œ ê°€ì¥ ë‚®ì€ ê³¨ì§œê¸° ì°¾ê¸°

```
ì„ í˜• ë¬¸ì œ:                ë¹„ì„ í˜• ë¬¸ì œ:
   â•²       â•±                    â•±â•²   â•±â•²
    â•²     â•±                    â•±  â•² â•±  â•²
     â•²   â•±                    â•±    â—    â•²
      â•² â•±                    â•±   ìµœì†Œì    â•²
       â—                    â—              â—
    í•œ ë²ˆì— ì°¾ìŒ           ì—¬ëŸ¬ ë²ˆ íƒìƒ‰ í•„ìš”!
```

**SLAMì—ì„œì˜ í•„ìš”ì„±**:
- **ì¬íˆ¬ì˜ ì˜¤ì°¨**: 3Dâ†’2D íˆ¬ì˜ì€ ë¹„ì„ í˜•
- **íšŒì „ í–‰ë ¬**: SO(3) ì—°ì‚°ì€ ë¹„ì„ í˜•
- **Bundle Adjustment**: ìˆ˜ì²œ ê°œ ë³€ìˆ˜ ë™ì‹œ ìµœì í™”

---

## ğŸ“– í•µì‹¬ ê°œë…

### 1. ë¹„ì„ í˜• vs ì„ í˜•

#### ì„ í˜• ë¬¸ì œ (Week 7)

```
Ax = b

â†’ ì •ê·œë°©ì •ì‹ Aáµ€Ax = Aáµ€b
â†’ í•œ ë²ˆì— í•´ë¥¼ êµ¬í•¨
```

#### ë¹„ì„ í˜• ë¬¸ì œ (ì´ë²ˆ ì£¼)

```
f(x) = z

fê°€ ë¹„ì„ í˜• í•¨ìˆ˜ì¼ ë•Œ:
â†’ ì •ê·œë°©ì •ì‹ ì‚¬ìš© ë¶ˆê°€!
â†’ ë°˜ë³µì  ì ‘ê·¼ í•„ìš”
```

**ë¹„ì„ í˜• ì˜ˆì‹œ**:
- y = aÂ·e^(bx) (ì§€ìˆ˜ í•¨ìˆ˜)
- p = KÂ·[R|t]Â·P (ì¹´ë©”ë¼ íˆ¬ì˜)
- R = exp(Î¸) (ë¡œë“œë¦¬ê²ŒìŠ¤ íšŒì „)

---

### 2. ì„ í˜•í™” (Linearization)

#### í•µì‹¬ ì•„ì´ë””ì–´

```
ë¹„ì„ í˜• í•¨ìˆ˜ë¥¼ í˜„ì¬ ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ "ì„ í˜• ê·¼ì‚¬"

f(x + Î”x) â‰ˆ f(x) + JÂ·Î”x
                â†‘
          Jacobian (ê¸°ìš¸ê¸° í–‰ë ¬)
```

**ë¹„ìœ **: ê³¡ì„  ë„ë¡œë¥¼ ì‘ì€ ì§ì„  ì¡°ê°ìœ¼ë¡œ ê·¼ì‚¬

```
ì‹¤ì œ ê³¡ì„ :          ì„ í˜• ê·¼ì‚¬:
    â•­â”€â•®                â•±
   â•±   â•²           ì ‘ì„ â•±
  â•±     â•²            â•±â†â”€â”€ í˜„ì¬ ìœ„ì¹˜
                    â•±
                   â•±
â†’ ì‘ì€ ë²”ìœ„ì—ì„œëŠ” ê·¼ì‚¬ê°€ ì˜ ë§ìŒ!
```

#### Jacobian í–‰ë ¬

```
J = âˆ‚f/âˆ‚x

    â¡ âˆ‚fâ‚/âˆ‚xâ‚  âˆ‚fâ‚/âˆ‚xâ‚‚  ...  âˆ‚fâ‚/âˆ‚xâ‚™ â¤
J = â¢ âˆ‚fâ‚‚/âˆ‚xâ‚  âˆ‚fâ‚‚/âˆ‚xâ‚‚  ...  âˆ‚fâ‚‚/âˆ‚xâ‚™ â¥
    â£   ...       ...    ...    ...   â¦

í¬ê¸°: mÃ—n (mê°œ í•¨ìˆ˜, nê°œ ë³€ìˆ˜)
```

**ì˜ˆì œ**: f = [aÂ·e^(bx)] ì˜ Jacobian

```
f(a, b) = aÂ·e^(bx)

âˆ‚f/âˆ‚a = e^(bx)
âˆ‚f/âˆ‚b = aÂ·xÂ·e^(bx)

J = [e^(bx),  aÂ·xÂ·e^(bx)]
```

---

### 3. Gauss-Newton ì•Œê³ ë¦¬ì¦˜

#### í•µì‹¬ ì•„ì´ë””ì–´

**ë¹„ì„ í˜• ë¬¸ì œë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì„ í˜•í™”í•˜ì—¬ í’€ê¸°**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Gauss-Newton í•œ ë‹¨ê³„             â”‚
â”‚                                         â”‚
â”‚  1. í˜„ì¬ xì—ì„œ Jacobian J ê³„ì‚°          â”‚
â”‚  2. ì”ì°¨ r = z - f(x) ê³„ì‚°              â”‚
â”‚  3. ì„ í˜•í™”ëœ ì •ê·œë°©ì •ì‹:                 â”‚
â”‚     (Jáµ€J)Â·Î”x = Jáµ€r                      â”‚
â”‚  4. ì—…ë°ì´íŠ¸: x â† x + Î”x                â”‚
â”‚  5. ìˆ˜ë ´í•  ë•Œê¹Œì§€ ë°˜ë³µ                   â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ì™œ Jáµ€Jì¸ê°€?

Week 7ì—ì„œëŠ” Aáµ€Aì˜€ëŠ”ë°:

```
ì„ í˜•:   Ax = b        â†’ Aáµ€Ax = Aáµ€b
ë¹„ì„ í˜•: f(x) â‰ˆ f(xâ‚€) + JÂ·Î”x = z
        â†’ Jáµ€JÂ·Î”x = Jáµ€(z - f(xâ‚€))
        â†’ Jáµ€JÂ·Î”x = Jáµ€r
```

**Jê°€ A ì—­í• ì„ í•¨!**

#### ì‹œê°í™”

```
ë°˜ë³µ 1:        ë°˜ë³µ 2:        ë°˜ë³µ 3:
    â•²              â•²              â•²
     â•²              â—              â—
      â—                            â”‚
    ì‹œì‘           ê·¼ì ‘          ìˆ˜ë ´!
```

#### ì½”ë“œ

```python
def gauss_newton(f, jacobian, x0, z, max_iter=10):
    x = x0.copy()
    
    for i in range(max_iter):
        J = jacobian(x)          # 1. Jacobian
        r = z - f(x)             # 2. ì”ì°¨
        
        # 3. ì •ê·œë°©ì •ì‹
        dx = np.linalg.solve(J.T @ J, J.T @ r)
        
        x = x + dx               # 4. ì—…ë°ì´íŠ¸
        
        if np.linalg.norm(dx) < 1e-8:
            break                # 5. ìˆ˜ë ´ í™•ì¸
    
    return x
```

---

### 4. Levenberg-Marquardt (LM)

#### Gauss-Newtonì˜ ë¬¸ì œ

```
ì´ˆê¸°ê°’ì´ ë©€ë©´ ë°œì‚°!

        ìµœì†Œì  â—
                â•²
                 â•²
          ì‹œì‘ì  â—â”€â”€â”€â”€â”€â”€â–¶ ë©€ë¦¬ ë– ë‚¨ ğŸ’¥
```

#### LMì˜ í•´ê²°ì±…

**Damping (ê°ì‡ ) ì¶”ê°€**:

```
(Jáµ€J + Î»I)Â·Î”x = Jáµ€r
       â†‘
   damping term
```

**Î»ì˜ ì—­í• **:

```
Î» í´ ë•Œ:                    Î» ì‘ì„ ë•Œ:
(Jáµ€J + Î»I) â‰ˆ Î»I            (Jáµ€J + Î»I) â‰ˆ Jáµ€J
â†’ Î”x = (1/Î»)Â·Jáµ€r           â†’ Î”x = (Jáµ€J)â»Â¹Jáµ€r
â†’ Gradient Descent!         â†’ Gauss-Newton!
â†’ ëŠë¦¬ì§€ë§Œ ì•ˆì •ì             â†’ ë¹ ë¥´ì§€ë§Œ ë¶ˆì•ˆì • ê°€ëŠ¥
```

#### ì ì‘ì  Î» ì¡°ì •

```
ë¹„ìš© ê°ì†Œ? â†’ Î» â†“ (ë” ê³µê²©ì , GNì— ê°€ê¹ê²Œ)
ë¹„ìš© ì¦ê°€? â†’ Î» â†‘ (ë” ë³´ìˆ˜ì , GDì— ê°€ê¹ê²Œ)
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            LM ì•Œê³ ë¦¬ì¦˜                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                        â”‚
â”‚    â”Œâ”€â–¶ Î”x ê³„ì‚° (Jáµ€J + Î»I)             â”‚
â”‚    â”‚                                   â”‚
â”‚    â”‚   ë¹„ìš© ê°ì†Œ?                       â”‚
â”‚    â”‚      â”‚                            â”‚
â”‚    â”‚   Yes â†“     No                    â”‚
â”‚    â”‚   x ì—…ë°ì´íŠ¸  â””â”€â”€â–¶ Î» *= 2        â”‚
â”‚    â”‚   Î» /= 2          â””â”€â”€â”            â”‚
â”‚    â”‚      â”‚                â”‚           â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                        â”‚
â”‚   ìˆ˜ë ´í•  ë•Œê¹Œì§€ ë°˜ë³µ                    â”‚
â”‚                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5. GN vs LM ë¹„êµ

| íŠ¹ì„± | Gauss-Newton | Levenberg-Marquardt |
|------|-------------|---------------------|
| ìˆ˜ë ´ ì†ë„ | **ë¹ ë¦„** | ì¤‘ê°„ |
| ì•ˆì •ì„± | ì´ˆê¸°ê°’ ë¯¼ê° | **ì•ˆì •ì ** |
| íŒŒë¼ë¯¸í„° | ì—†ìŒ | Î» (ìë™ ì¡°ì •) |
| ì‚¬ìš©ì²˜ | ì¢‹ì€ ì´ˆê¸°ê°’ ìˆì„ ë•Œ | **ì¼ë°˜ì  ìƒí™©** |

**ê²°ë¡ **: ì‹¤ì „ì—ì„œëŠ” ëŒ€ë¶€ë¶„ LM ì‚¬ìš©

---

### 6. Ceres Solver

#### ì†Œê°œ

Googleì´ ê°œë°œí•œ C++ ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
- SLAM í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
- ìë™ ë¯¸ë¶„ ì§€ì›
- ëŒ€ê·œëª¨ í¬ì†Œ ë¬¸ì œ ì²˜ë¦¬

#### ê¸°ë³¸ êµ¬ì¡°

```cpp
// 1. ë¹„ìš© í•¨ìˆ˜ ì •ì˜
struct MyCost {
    MyCost(double x, double y) : x_(x), y_(y) {}
    
    template <typename T>
    bool operator()(const T* params, T* residual) const {
        // residual = ì¸¡ì •ê°’ - ì˜ˆì¸¡ê°’
        residual[0] = y_ - params[0] * exp(params[1] * x_);
        return true;
    }
    
    double x_, y_;
};

// 2. Problemì— ì¶”ê°€
ceres::Problem problem;
for (auto& data : dataset) {
    problem.AddResidualBlock(
        new ceres::AutoDiffCostFunction<MyCost, 1, 2>(
            new MyCost(data.x, data.y)),
        nullptr,   // loss function
        params);   // ìµœì í™”í•  ë³€ìˆ˜
}

// 3. ìµœì í™” ì‹¤í–‰
ceres::Solver::Options options;
options.linear_solver_type = ceres::DENSE_QR;
ceres::Solver::Summary summary;
ceres::Solve(options, &problem, &summary);
```

#### Python ëŒ€ì•ˆ: scipy

```python
from scipy.optimize import least_squares

def residual(params, x, y):
    a, b = params
    return y - a * np.exp(b * x)

result = least_squares(
    residual, 
    x0=[1, 0.5], 
    args=(x_data, y_data),
    method='lm'  # Levenberg-Marquardt
)
```

---

### 7. Ceres Solver ì„¤ì¹˜ ë° ì‹¤ìŠµ

#### 7.1 ì„¤ì¹˜ ë°©ë²•

##### macOS

```bash
# Homebrew ì‚¬ìš©
brew install ceres-solver

# ë˜ëŠ” ì†ŒìŠ¤ì—ì„œ ë¹Œë“œ
git clone https://ceres-solver.googlesource.com/ceres-solver
cd ceres-solver
mkdir build && cd build
cmake ..
make -j4
sudo make install
```

##### Ubuntu/Debian

```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
sudo apt-get install cmake libgoogle-glog-dev libgflags-dev
sudo apt-get install libatlas-base-dev libeigen3-dev libsuitesparse-dev

# Ceres Solver ì„¤ì¹˜
sudo apt-get install libceres-dev

# ë˜ëŠ” ì†ŒìŠ¤ì—ì„œ ë¹Œë“œ
git clone https://ceres-solver.googlesource.com/ceres-solver
cd ceres-solver
mkdir build && cd build
cmake ..
make -j4
sudo make install
```

##### Windows

```bash
# vcpkg ì‚¬ìš© (ê¶Œì¥)
vcpkg install ceres

# ë˜ëŠ” CMake GUIë¡œ ì†ŒìŠ¤ ë¹Œë“œ
# https://github.com/ceres-solver/ceres-solver/releases
```

#### 7.2 ê¸°ë³¸ ì‚¬ìš©ë²•

##### ë‹¨ê³„ë³„ ì„¤ëª…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Ceres Solver ì‚¬ìš© íë¦„             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  1. ë¹„ìš© í•¨ìˆ˜ ì •ì˜ (CostFunction)        â”‚
â”‚     â†“                                   â”‚
â”‚  2. Problem ê°ì²´ ìƒì„±                   â”‚
â”‚     â†“                                   â”‚
â”‚  3. ResidualBlock ì¶”ê°€                  â”‚
â”‚     â†“                                   â”‚
â”‚  4. Solver Options ì„¤ì •                 â”‚
â”‚     â†“                                   â”‚
â”‚  5. Solve() ì‹¤í–‰                        â”‚
â”‚     â†“                                   â”‚
â”‚  6. Summary í™•ì¸                        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

##### ì™„ì „í•œ ê³¡ì„  í”¼íŒ… ì˜ˆì œ

**ë¬¸ì œ**: y = aÂ·e^(bÂ·x) í˜•íƒœì˜ ê³¡ì„  í”¼íŒ…

**curve_fitting.cpp**:

```cpp
#include <iostream>
#include <ceres/ceres.h>
#include <vector>
#include <cmath>
#include <random>

// 1ï¸âƒ£ ë¹„ìš© í•¨ìˆ˜ ì •ì˜
struct ExponentialResidual {
    ExponentialResidual(double x, double y)
        : x_(x), y_(y) {}
    
    // Ceresê°€ í˜¸ì¶œí•  í•¨ìˆ˜
    // params[0] = a, params[1] = b
    template <typename T>
    bool operator()(const T* const params, T* residual) const {
        // residual = ì¸¡ì •ê°’ - ì˜ˆì¸¡ê°’
        residual[0] = T(y_) - params[0] * exp(params[1] * T(x_));
        return true;
    }
    
    // Factory method for AutoDiffCostFunction
    static ceres::CostFunction* Create(double x, double y) {
        return new ceres::AutoDiffCostFunction<ExponentialResidual, 1, 2>(
            new ExponentialResidual(x, y));
    }
    
private:
    const double x_;
    const double y_;
};

int main() {
    // ğŸ² ë°ì´í„° ìƒì„± (ì‹¤ì œ ê°’: a=2.5, b=0.3)
    std::vector<double> x_data, y_data;
    std::default_random_engine generator;
    std::normal_distribution<double> noise(0.0, 0.1);
    
    const double true_a = 2.5;
    const double true_b = 0.3;
    
    for (int i = 0; i < 50; ++i) {
        double x = i * 0.1;
        double y = true_a * exp(true_b * x) + noise(generator);
        x_data.push_back(x);
        y_data.push_back(y);
    }
    
    // 2ï¸âƒ£ ì´ˆê¸° ì¶”ì •ê°’ (ì¼ë¶€ëŸ¬ í‹€ë¦¬ê²Œ)
    double params[2] = {1.0, 0.1};
    
    std::cout << "ì´ˆê¸°ê°’: a = " << params[0] 
              << ", b = " << params[1] << std::endl;
    
    // 3ï¸âƒ£ Problem ìƒì„±
    ceres::Problem problem;
    
    // 4ï¸âƒ£ ê° ë°ì´í„° í¬ì¸íŠ¸ì— ëŒ€í•´ ResidualBlock ì¶”ê°€
    for (size_t i = 0; i < x_data.size(); ++i) {
        ceres::CostFunction* cost_function = 
            ExponentialResidual::Create(x_data[i], y_data[i]);
        
        problem.AddResidualBlock(
            cost_function,      // ë¹„ìš© í•¨ìˆ˜
            nullptr,            // loss function (nullptr = squared loss)
            params);            // ìµœì í™”í•  ë³€ìˆ˜
    }
    
    // 5ï¸âƒ£ Solver ì˜µì…˜ ì„¤ì •
    ceres::Solver::Options options;
    options.linear_solver_type = ceres::DENSE_QR;
    options.minimizer_progress_to_stdout = true;
    options.max_num_iterations = 100;
    
    // 6ï¸âƒ£ ìµœì í™” ì‹¤í–‰
    ceres::Solver::Summary summary;
    ceres::Solve(options, &problem, &summary);
    
    // 7ï¸âƒ£ ê²°ê³¼ ì¶œë ¥
    std::cout << "\n" << summary.BriefReport() << "\n\n";
    std::cout << "ìµœì í™” ê²°ê³¼:\n";
    std::cout << "  a = " << params[0] << " (ì‹¤ì œ: " << true_a << ")\n";
    std::cout << "  b = " << params[1] << " (ì‹¤ì œ: " << true_b << ")\n";
    
    return 0;
}
```

**CMakeLists.txt**:

```cmake
cmake_minimum_required(VERSION 3.10)
project(ceres_example)

set(CMAKE_CXX_STANDARD 14)

# Ceres ì°¾ê¸°
find_package(Ceres REQUIRED)

# ì‹¤í–‰ íŒŒì¼
add_executable(curve_fitting curve_fitting.cpp)
target_link_libraries(curve_fitting Ceres::ceres)
```

**ë¹Œë“œ ë° ì‹¤í–‰**:

```bash
mkdir build && cd build
cmake ..
make
./curve_fitting
```

**ì¶œë ¥ ì˜ˆì‹œ**:

```
ì´ˆê¸°ê°’: a = 1, b = 0.1

iter      cost      cost_change  |gradient|   |step|    tr_ratio  tr_radius  ls_iter  iter_time  total_time
   0  9.842456e+02    0.00e+00    1.23e+03   0.00e+00   0.00e+00  1.00e+04        0    1.23e-04    2.45e-04
   1  1.234567e+01    9.72e+02    5.67e+01   1.23e+00   9.99e-01  3.00e+04        1    3.45e-04    5.92e-04
   2  2.345678e+00    9.99e+00    1.23e+01   2.34e-01   9.99e-01  9.00e+04        1    2.12e-04    8.15e-04
   ...
  10  1.234567e-02    5.67e-03    1.23e-03   1.23e-04   1.00e+00  2.70e+08        1    1.98e-04    2.34e-03

Ceres Solver Report: Iterations: 11, Initial cost: 9.842e+02, Final cost: 1.235e-02

ìµœì í™” ê²°ê³¼:
  a = 2.498 (ì‹¤ì œ: 2.5)
  b = 0.301 (ì‹¤ì œ: 0.3)
```

#### 7.3 í•µì‹¬ ê°œë… ì„¤ëª…

##### AutoDiffCostFunction

```cpp
// template <ë¹„ìš©í•¨ìˆ˜íƒ€ì…, ì”ì°¨ì°¨ì›, íŒŒë¼ë¯¸í„°1ì°¨ì›, íŒŒë¼ë¯¸í„°2ì°¨ì›, ...>
ceres::AutoDiffCostFunction<ExponentialResidual, 1, 2>
                                                  â†‘  â†‘
                                                  â”‚  â””â”€ 2ê°œ íŒŒë¼ë¯¸í„° (a, b)
                                                  â””â”€â”€â”€ 1ì°¨ì› ì”ì°¨ (scalar)
```

**ìë™ ë¯¸ë¶„ì˜ ì¥ì **:
- ìˆ˜ë™ìœ¼ë¡œ Jacobian ê³„ì‚° ë¶ˆí•„ìš”
- ì‹¤ìˆ˜ ë°©ì§€, ìœ ì§€ë³´ìˆ˜ ì‰¬ì›€
- Jet íƒ€ì…ìœ¼ë¡œ forward automatic differentiation

##### Loss Function

```cpp
// Squared Loss (ê¸°ë³¸)
nullptr

// Huber Loss (outlier ê°•ê±´)
new ceres::HuberLoss(1.0)

// Cauchy Loss (ë” ê°•ê±´)
new ceres::CauchyLoss(1.0)
```

**ì–¸ì œ ì“°ë‚˜?**
- `nullptr`: ë°ì´í„°ê°€ ê¹¨ë—í•  ë•Œ
- `HuberLoss`: SLAMì—ì„œ ì¼ë°˜ì  (outlier ìˆì„ ë•Œ)
- `CauchyLoss`: outlierê°€ ë§¤ìš° ë§ì„ ë•Œ

##### Solver Options ì£¼ìš” ì„¤ì •

```cpp
ceres::Solver::Options options;

// ì„ í˜• ì†”ë²„ ì„ íƒ
options.linear_solver_type = ceres::DENSE_QR;        // ì‘ì€ ë¬¸ì œ
options.linear_solver_type = ceres::SPARSE_NORMAL_CHOLESKY;  // í° ë¬¸ì œ
options.linear_solver_type = ceres::DENSE_SCHUR;     // Bundle Adjustment

// Trust region ì „ëµ
options.trust_region_strategy_type = ceres::LEVENBERG_MARQUARDT;  // ê¸°ë³¸
options.trust_region_strategy_type = ceres::DOGLEG;

// ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
options.max_num_iterations = 100;

// ìˆ˜ë ´ ê¸°ì¤€
options.function_tolerance = 1e-6;
options.gradient_tolerance = 1e-10;
options.parameter_tolerance = 1e-8;

// ë¡œê·¸ ì¶œë ¥
options.minimizer_progress_to_stdout = true;
```

#### 7.4 ì‹¤ì „ íŒ

##### âœ… Best Practices

```cpp
// 1. ì¢‹ì€ ì´ˆê¸°ê°’ ì œê³µ
double params[2] = {1.0, 0.1};  // âŒ ë„ˆë¬´ ë©€ ìˆ˜ ìˆìŒ
double params[2] = {2.0, 0.2};  // âœ… ëŒ€ëµì  ì‚¬ì „ ì§€ì‹ í™œìš©

// 2. íŒŒë¼ë¯¸í„° ë²”ìœ„ ì œí•œ
problem.SetParameterLowerBound(params, 0, 0.0);   // a > 0
problem.SetParameterUpperBound(params, 0, 10.0);  // a < 10

// 3. íŠ¹ì • íŒŒë¼ë¯¸í„° ê³ ì •
problem.SetParameterBlockConstant(params);

// 4. Loss function ì‚¬ìš© (outlier ëŒ€ì‘)
problem.AddResidualBlock(
    cost_function,
    new ceres::HuberLoss(1.0),  // âœ…
    params);
```

##### âš ï¸ ì£¼ì˜ì‚¬í•­

```cpp
// âŒ ì˜ëª»ëœ ì˜ˆ: ë©”ëª¨ë¦¬ ê´€ë¦¬
ceres::CostFunction* cost = ExponentialResidual::Create(x, y);
delete cost;  // âŒ Ceresê°€ ìë™ìœ¼ë¡œ ê´€ë¦¬í•¨!

// âœ… ì˜¬ë°”ë¥¸ ì˜ˆ
problem.AddResidualBlock(cost, nullptr, params);
// Ceresê°€ ì†Œë©¸ìì—ì„œ ìë™ í•´ì œ

// âŒ ì˜ëª»ëœ ì˜ˆ: íŒŒë¼ë¯¸í„° ë²”ìœ„
double params[2];
// ... solve ...
// paramsê°€ ìŠ¤íƒ ë³€ìˆ˜ë¼ë©´ í•¨ìˆ˜ ëë‚˜ë©´ ì†Œë©¸! 

// âœ… ì˜¬ë°”ë¥¸ ì˜ˆ: ì¶©ë¶„í•œ ìƒëª…ì£¼ê¸° ë³´ì¥
std::vector<double> params(2);
// ë˜ëŠ” heap í• ë‹¹
```

---

### 8. SLAMì—ì„œì˜ í™œìš©

#### Bundle Adjustment

```
           ì¹´ë©”ë¼ 1        ì¹´ë©”ë¼ 2        ì¹´ë©”ë¼ 3
              â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—
             â•±â”‚â•²            â•±â”‚â•²            â•±â”‚â•²
            â•± â”‚ â•²          â•± â”‚ â•²          â•± â”‚ â•²
           â•±  â”‚  â•²        â•±  â”‚  â•²        â•±  â”‚  â•²
          â˜…   â˜…  â˜…     â˜…   â˜…   â˜…     â˜…   â˜…  â˜…
          
       ë™ì‹œì— ìµœì í™”:
       - ëª¨ë“  ì¹´ë©”ë¼ í¬ì¦ˆ (R, t)
       - ëª¨ë“  3D ì  ìœ„ì¹˜
       - ì¬íˆ¬ì˜ ì˜¤ì°¨ ìµœì†Œí™”
```

#### VINS-Fusionì—ì„œ

```cpp
// vins_estimator/src/factor/projection_factor.h

// ì¬íˆ¬ì˜ ì˜¤ì°¨ ë¹„ìš© í•¨ìˆ˜
class ProjectionFactor : public ceres::SizedCostFunction<2, 7, 7, 7, 1> {
    // ì”ì°¨: ê´€ì¸¡ëœ 2Dì  - íˆ¬ì˜ëœ 2Dì 
    // Jacobian: ìë™ ë¯¸ë¶„ ë˜ëŠ” ë¶„ì„ì  ê³„ì‚°
};

// optimization.cpp
ceres::Problem problem;

// ì¹´ë©”ë¼ í¬ì¦ˆ íŒŒë¼ë¯¸í„°
for (auto& frame : frames) {
    problem.AddParameterBlock(frame.pose, 7);
}

// ì¬íˆ¬ì˜ ì˜¤ì°¨ ì¶”ê°€
for (auto& obs : observations) {
    problem.AddResidualBlock(
        new ProjectionFactor(...),
        loss_function,
        pose_i, pose_j, inv_depth);
}

ceres::Solve(options, &problem, &summary);
```

---

## ğŸ’» ì‹¤ìŠµ íŒŒì¼

| íŒŒì¼ | ë‚´ìš© | ë‚œì´ë„ |
|------|------|--------|
| `nonlinear_basics.py` | Gauss-Newton, ê³¡ì„  í”¼íŒ… | â­â­â­ |
| `nonlinear_quiz.py` | LM, scipy í™œìš© | â­â­â­ |

---

## ğŸ“Š í•µì‹¬ ì •ë¦¬

### ì•Œê³ ë¦¬ì¦˜ ìš”ì•½

| ì•Œê³ ë¦¬ì¦˜ | ì •ê·œë°©ì •ì‹ | íŠ¹ì§• |
|---------|-----------|------|
| ì„ í˜• LS | Aáµ€Ax = Aáµ€b | í•œ ë²ˆì— í•´ê²° |
| Gauss-Newton | Jáµ€JÂ·Î”x = Jáµ€r | ë°˜ë³µ, ë¹ ë¦„ |
| LM | (Jáµ€J + Î»I)Î”x = Jáµ€r | ë°˜ë³µ, ì•ˆì •ì  |

### í•µì‹¬ í¬ì¸íŠ¸

```
1. ë¹„ì„ í˜• â†’ ì„ í˜•í™” (Jacobian)
2. ë°˜ë³µì  ì ‘ê·¼ (ìˆ˜ë ´í•  ë•Œê¹Œì§€)
3. GN: ë¹ ë¥´ì§€ë§Œ ì´ˆê¸°ê°’ ë¯¼ê°
4. LM: Î»ë¡œ ì•ˆì •ì„±-ì†ë„ ê· í˜•
5. Ceres: SLAM ì‹¤ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬
```

---

## âœ… í•™ìŠµ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ì´ˆ ì´í•´ (í•„ìˆ˜)
- [ ] ì„ í˜•í™”ì™€ Jacobian ê´€ê³„ ì„¤ëª… ê°€ëŠ¥
- [ ] Gauss-Newton í•œ ìŠ¤í… ì„¤ëª… ê°€ëŠ¥
- [ ] LMì´ GNë³´ë‹¤ ì•ˆì •ì ì¸ ì´ìœ  ì„¤ëª… ê°€ëŠ¥

### ì‹¤ìš© í™œìš© (ê¶Œì¥)
- [ ] Jacobian ê³„ì‚° ê°€ëŠ¥
- [ ] scipy.optimize.least_squares ì‚¬ìš© ê°€ëŠ¥
- [ ] ìˆ˜ë ´ ì—¬ë¶€ íŒë‹¨ ê°€ëŠ¥

### ì‹¬í™” (ì„ íƒ)
- [ ] Ceres CostFunction êµ¬ì¡° ì´í•´
- [ ] Hessian â‰ˆ Jáµ€J ê·¼ì‚¬ì˜ ì˜ë¯¸ ì´í•´
- [ ] VINS ìµœì í™” ì½”ë“œ íë¦„ ë¶„ì„

---

## ğŸ”— Phase 1 ì™„ë£Œ! ğŸ‰

8ì£¼ê°„ì˜ ìˆ˜í•™ í•µì‹¬ í•™ìŠµì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤:

| ì£¼ì°¨ | ì£¼ì œ | í•µì‹¬ |
|------|------|------|
| 1-2 | ì„ í˜•ëŒ€ìˆ˜ | ë²¡í„°, í–‰ë ¬, SVD |
| 3 | SVD í™œìš© | Null space, rank |
| 4-5 | í™•ë¥ /ë² ì´ì¦ˆ | ê°€ìš°ì‹œì•ˆ, ì¶”ì • |
| 6 | 3D ë³€í™˜ | SO(3), SE(3), Lie |
| 7 | ìµœì†ŒììŠ¹ | Aáµ€Ax = Aáµ€b |
| **8** | **ë¹„ì„ í˜• ìµœì í™”** | **GN, LM, Ceres ì„¤ì¹˜/ì‹¤ìŠµ** |

**ë‹¤ìŒ: Phase 2 - ì»´í“¨í„° ë¹„ì „ ê¸°ì´ˆ! ğŸš€**

---

## ğŸ“š ì°¸ê³  ìë£Œ

- Numerical Optimization (Nocedal & Wright)
- Ceres Solver Documentation
- VINS-Fusion optimization.cpp

---

## â“ FAQ

**Q1: Jacobianì€ ì–´ë–»ê²Œ êµ¬í•˜ë‚˜ìš”?**
A: ë¶„ì„ì  ë¯¸ë¶„(ì†ê³„ì‚°) ë˜ëŠ” ìë™ ë¯¸ë¶„(Ceres AutoDiff).

**Q2: GNì´ ë°œì‚°í•˜ë©´ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆë‚˜ìš”?**
A: ë¹„ìš© í•¨ìˆ˜ê°€ ì¦ê°€í•˜ê±°ë‚˜, íŒŒë¼ë¯¸í„°ê°€ ë°œì‚°.

**Q3: Î» ì´ˆê¸°ê°’ì€ ì–´ë–»ê²Œ ì •í•˜ë‚˜ìš”?**
A: ë³´í†µ 0.01~1. ìë™ ì¡°ì •ë˜ë¯€ë¡œ í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ.

**Q4: SLAMì—ì„œ GN vs LM?**
A: ëŒ€ë¶€ë¶„ LM. í•˜ì§€ë§Œ BAì—ì„œëŠ” GN + trust region ì¡°í•©ë„ ë§ì´ ì‚¬ìš©.

---

**ğŸ¯ Week 8 í•µì‹¬ ë©”ì‹œì§€:**

> ë¹„ì„ í˜• ë¬¸ì œ = ë°˜ë³µì  ì„ í˜•í™”
>
> **Gauss-Newton**: Jáµ€JÂ·Î”x = Jáµ€r
> **LM**: (Jáµ€J + Î»I)Â·Î”x = Jáµ€r
>
> SLAM ìµœì í™”ì˜ ì—”ì§„!
