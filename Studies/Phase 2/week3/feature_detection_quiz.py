"""
Phase 2 - Week 3: íŠ¹ì§•ì  ê²€ì¶œ ì‹¤ìŠµ ë¬¸ì œ
======================================
íŒŒë¼ë¯¸í„° íŠœë‹, ì•Œê³ ë¦¬ì¦˜ ë¹„êµ, NMS êµ¬í˜„

í•™ìŠµ ëª©í‘œ:
1. íŒŒë¼ë¯¸í„°ê°€ ê²€ì¶œì— ë¯¸ì¹˜ëŠ” ì˜í–¥
2. Non-maximum Suppression êµ¬í˜„
3. ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë¹„êµ
4. íŠ¹ì§•ì  ë¶„í¬ ë¶„ì„

ì‹¤í–‰ ì‹œê°„: ì•½ 2ë¶„
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import uniform_filter, maximum_filter

np.set_printoptions(precision=4, suppress=True)
np.random.seed(42)

print("=" * 70)
print("       Phase 2 - Week 3: íŠ¹ì§•ì  ê²€ì¶œ ì‹¤ìŠµ ë¬¸ì œ")
print("=" * 70)
print("\nì´ ì‹¤ìŠµì—ì„œëŠ” íŠ¹ì§•ì  ê²€ì¶œì„ ë” ê¹Šì´ íƒêµ¬í•©ë‹ˆë‹¤.\n")

# ============================================================
# ê¸°ë³¸ í•¨ìˆ˜
# ============================================================
def harris_corner_detector(image, k=0.04, window_size=3, threshold=0.01):
    """Harris ì½”ë„ˆ ê²€ì¶œ"""
    Ix = np.zeros_like(image)
    Iy = np.zeros_like(image)
    Ix[:, 1:-1] = (image[:, 2:] - image[:, :-2]) / 2
    Iy[1:-1, :] = (image[2:, :] - image[:-2, :]) / 2
    
    Ixx = uniform_filter(Ix * Ix, size=window_size)
    Iyy = uniform_filter(Iy * Iy, size=window_size)
    Ixy = uniform_filter(Ix * Iy, size=window_size)
    
    det = Ixx * Iyy - Ixy * Ixy
    trace = Ixx + Iyy
    R = det - k * trace * trace
    
    return R

def create_test_image_with_noise(size=200, noise_level=0):
    """ë…¸ì´ì¦ˆê°€ ìˆëŠ” í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€"""
    img = np.ones((size, size), dtype=np.float32) * 128
    
    # í¬ê¸°ì— ë§ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì •
    if size >= 200:
        img[40:80, 40:100] = 200
        for i in range(40):
            if 100+i < size and 120+i < size:
                img[100+i, max(0, 120-i):min(size, 120+i+1)] = 50
        
        for i in range(4):
            for j in range(4):
                if (i + j) % 2 == 0:
                    y1, y2 = 130+i*15, min(size, 130+(i+1)*15)
                    x1, x2 = 130+j*15, min(size, 130+(j+1)*15)
                    if y1 < size and x1 < size:
                        img[y1:y2, x1:x2] = 30
    else:
        # ì‘ì€ ì´ë¯¸ì§€ìš© ê°„ë‹¨ íŒ¨í„´
        img[size//5:size//3, size//5:size//2] = 200
        img[size//2:size*2//3, size//3:size*2//3] = 50
    
    if noise_level > 0:
        img += np.random.randn(size, size) * noise_level
        img = np.clip(img, 0, 255)
    
    return img

# ============================================================
# ë¬¸ì œ 1: Non-maximum Suppression
# ============================================================
print("\n" + "=" * 70)
print("ë¬¸ì œ 1: Non-maximum Suppression (NMS)")
print("=" * 70)

print("""
ğŸ¯ ëª©í‘œ: ë°€ì§‘ëœ ì½”ë„ˆë“¤ ì¤‘ ìµœëŒ€ê°’ë§Œ ë‚¨ê¸°ê¸°

ë¬¸ì œ:
- Harris ì‘ë‹µì´ ì½”ë„ˆ ì£¼ë³€ì—ì„œ ë†’ìŒ
- ì—¬ëŸ¬ í”½ì…€ì´ ê°™ì€ ì½”ë„ˆë¡œ ê²€ì¶œë¨
- í•˜ë‚˜ì˜ ì½”ë„ˆ = í•˜ë‚˜ì˜ ì ë§Œ í•„ìš”!

í•´ê²°: NMS
- ì§€ì—­ ìœˆë„ìš° ë‚´ ìµœëŒ€ê°’ë§Œ ìœ ì§€
- ë‚˜ë¨¸ì§€ëŠ” ì–µì œ
""")

def non_maximum_suppression(response, window_size=5, threshold=0.01):
    """
    Non-maximum Suppression êµ¬í˜„
    
    Args:
        response: Harris ì‘ë‹µ ë§µ
        window_size: ì§€ì—­ ìµœëŒ€ ê²€ìƒ‰ ìœˆë„ìš°
        threshold: ì‘ë‹µ ì„ê³„ê°’ (ë¹„ìœ¨)
    
    Returns:
        corners: (N, 2) ì½”ë„ˆ ì¢Œí‘œ [(x, y), ...]
    """
    # ì§€ì—­ ìµœëŒ€ í•„í„°
    local_max = maximum_filter(response, size=window_size)
    
    # ì§€ì—­ ìµœëŒ€ì´ë©´ì„œ ì„ê³„ê°’ ì´ìƒì¸ ì 
    thresh_value = threshold * response.max()
    
    corners_mask = (response == local_max) & (response > thresh_value)
    
    # ì¢Œí‘œ ì¶”ì¶œ
    coords = np.argwhere(corners_mask)
    corners = [(c[1], c[0]) for c in coords]  # (x, y)
    
    return corners

# í…ŒìŠ¤íŠ¸
test_img = create_test_image_with_noise(200, noise_level=0)
R = harris_corner_detector(test_img, threshold=0.01)

# NMS ì „í›„ ë¹„êµ
corners_before = np.argwhere(R > 0.01 * R.max())
corners_after = non_maximum_suppression(R, window_size=7, threshold=0.01)

print(f"\nNMS íš¨ê³¼:")
print(f"  NMS ì „: {len(corners_before)} ì ")
print(f"  NMS í›„: {len(corners_after)} ì ")
print(f"  ì œê±°ëœ ì¤‘ë³µ: {len(corners_before) - len(corners_after)} ì ")

# ì‹œê°í™”
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

ax1 = axes[0]
ax1.imshow(test_img, cmap='gray')
ax1.set_title('Original Image', fontsize=12)
ax1.axis('off')

ax2 = axes[1]
ax2.imshow(test_img, cmap='gray')
for y, x in corners_before[:100]:
    ax2.plot(x, y, 'r.', markersize=3)
ax2.set_title(f'Before NMS ({len(corners_before)} points)', fontsize=12)
ax2.axis('off')

ax3 = axes[2]
ax3.imshow(test_img, cmap='gray')
for x, y in corners_after:
    ax3.plot(x, y, 'g.', markersize=8)
ax3.set_title(f'After NMS ({len(corners_after)} points)', fontsize=12)
ax3.axis('off')

plt.tight_layout()
plt.savefig('/Users/yeonge/SynologyDrive/1. YeongE/7. Visual SLAM Study/visual-slam-learning/Studies/Phase 2/week3/nms_comparison.png', dpi=150)
print("NMS comparison saved: nms_comparison.png")

# ============================================================
# ë¬¸ì œ 2: íŒŒë¼ë¯¸í„° íŠœë‹
# ============================================================
print("\n" + "=" * 70)
print("ë¬¸ì œ 2: íŒŒë¼ë¯¸í„° íŠœë‹ íš¨ê³¼")
print("=" * 70)

print("""
ğŸ¯ ëª©í‘œ: thresholdê°€ ê²€ì¶œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„

threshold â†‘ â†’ ì ì€ ê²€ì¶œ, ê°•í•œ ì½”ë„ˆë§Œ
threshold â†“ â†’ ë§ì€ ê²€ì¶œ, ì•½í•œ ì½”ë„ˆë„
""")

thresholds = [0.001, 0.01, 0.05, 0.1]
detection_counts = []

print("\nThresholdì— ë”°ë¥¸ ê²€ì¶œ ìˆ˜:")
print("-" * 40)

for thresh in thresholds:
    corners = non_maximum_suppression(R, window_size=7, threshold=thresh)
    detection_counts.append(len(corners))
    print(f"  threshold = {thresh:.3f}: {len(corners):4d} corners")

# ì‹œê°í™”
fig, axes = plt.subplots(1, 4, figsize=(16, 4))

for idx, thresh in enumerate(thresholds):
    corners = non_maximum_suppression(R, window_size=7, threshold=thresh)
    
    ax = axes[idx]
    ax.imshow(test_img, cmap='gray')
    for x, y in corners:
        ax.plot(x, y, 'r.', markersize=5)
    ax.set_title(f'threshold = {thresh}\n({len(corners)} corners)', fontsize=11)
    ax.axis('off')

plt.tight_layout()
plt.savefig('/Users/yeonge/SynologyDrive/1. YeongE/7. Visual SLAM Study/visual-slam-learning/Studies/Phase 2/week3/threshold_tuning.png', dpi=150)
print("Threshold tuning saved: threshold_tuning.png")

# ============================================================
# ë¬¸ì œ 3: ë…¸ì´ì¦ˆ ê°•ê±´ì„±
# ============================================================
print("\n" + "=" * 70)
print("ë¬¸ì œ 3: ë…¸ì´ì¦ˆì— ëŒ€í•œ ê°•ê±´ì„±")
print("=" * 70)

print("""
ğŸ¯ ëª©í‘œ: ë…¸ì´ì¦ˆê°€ íŠ¹ì§•ì  ê²€ì¶œì— ë¯¸ì¹˜ëŠ” ì˜í–¥

ì‹¤ì œ ì¹´ë©”ë¼ ì´ë¯¸ì§€:
- ì„¼ì„œ ë…¸ì´ì¦ˆ ì¡´ì¬
- ì¡°ëª… ë³€í™”
- ëª¨ì…˜ ë¸”ëŸ¬

ê°•ê±´í•œ ê²€ì¶œê¸°ê°€ í•„ìš”!
""")

noise_levels = [0, 10, 30, 50]

print("\në…¸ì´ì¦ˆ ìˆ˜ì¤€ì— ë”°ë¥¸ ê²€ì¶œ:")
print("-" * 40)

fig, axes = plt.subplots(2, 4, figsize=(16, 8))

for idx, noise in enumerate(noise_levels):
    # ë…¸ì´ì¦ˆ ì´ë¯¸ì§€ ìƒì„±
    noisy_img = create_test_image_with_noise(200, noise_level=noise)
    
    # Harris ê²€ì¶œ
    R_noisy = harris_corner_detector(noisy_img)
    corners = non_maximum_suppression(R_noisy, window_size=7, threshold=0.01)
    
    print(f"  noise = {noise:2d}: {len(corners):4d} corners")
    
    # ì‹œê°í™”
    axes[0, idx].imshow(noisy_img, cmap='gray')
    axes[0, idx].set_title(f'Noise = {noise}', fontsize=11)
    axes[0, idx].axis('off')
    
    axes[1, idx].imshow(noisy_img, cmap='gray')
    for x, y in corners:
        axes[1, idx].plot(x, y, 'r.', markersize=4)
    axes[1, idx].set_title(f'{len(corners)} corners', fontsize=11)
    axes[1, idx].axis('off')

plt.tight_layout()
plt.savefig('/Users/yeonge/SynologyDrive/1. YeongE/7. Visual SLAM Study/visual-slam-learning/Studies/Phase 2/week3/noise_robustness.png', dpi=150)
print("Noise robustness saved: noise_robustness.png")

# ============================================================
# ë¬¸ì œ 4: íŠ¹ì§•ì  ë¶„í¬
# ============================================================
print("\n" + "=" * 70)
print("ë¬¸ì œ 4: íŠ¹ì§•ì  ë¶„í¬ ë¶„ì„")
print("=" * 70)

print("""
ğŸ¯ ëª©í‘œ: ì´ë¯¸ì§€ ì „ì²´ì— ê· ì¼í•˜ê²Œ ë¶„í¬ì‹œí‚¤ê¸°

ë¬¸ì œ: íŠ¹ì§•ì ì´ í•œ ê³³ì— ëª°ë¦¼
í•´ê²°: ê·¸ë¦¬ë“œ ê¸°ë°˜ ê²€ì¶œ ë˜ëŠ” ìµœì†Œ ê±°ë¦¬ ì œì•½

VINS íŒŒë¼ë¯¸í„°: min_dist = 30 (í”½ì…€)
""")

def enforce_min_distance(corners, min_dist=30):
    """ìµœì†Œ ê±°ë¦¬ ì œì•½ ì ìš©"""
    if len(corners) == 0:
        return []
    
    selected = [corners[0]]
    
    for c in corners[1:]:
        too_close = False
        for s in selected:
            dist = np.sqrt((c[0] - s[0])**2 + (c[1] - s[1])**2)
            if dist < min_dist:
                too_close = True
                break
        
        if not too_close:
            selected.append(c)
    
    return selected

# ìµœì†Œ ê±°ë¦¬ ì ìš©
R_clean = harris_corner_detector(test_img)
corners_all = non_maximum_suppression(R_clean, window_size=5, threshold=0.01)

# ì‘ë‹µ ê°•ë„ë¡œ ì •ë ¬ (ê°•í•œ ê²ƒë¶€í„°)
corners_sorted = sorted(corners_all, 
                        key=lambda c: R_clean[c[1], c[0]], 
                        reverse=True)

corners_spaced = enforce_min_distance(corners_sorted, min_dist=20)

print(f"\nìµœì†Œ ê±°ë¦¬ ì œì•½:")
print(f"  ì ìš© ì „: {len(corners_all)} points")
print(f"  min_dist=20 ì ìš© í›„: {len(corners_spaced)} points")

# ì‹œê°í™”
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

ax1 = axes[0]
ax1.imshow(test_img, cmap='gray')
for x, y in corners_all:
    ax1.plot(x, y, 'r.', markersize=5)
ax1.set_title(f'Without Min Distance ({len(corners_all)} pts)', fontsize=12)
ax1.axis('off')

ax2 = axes[1]
ax2.imshow(test_img, cmap='gray')
for x, y in corners_spaced:
    ax2.plot(x, y, 'g.', markersize=8)
ax2.set_title(f'With Min Distance 20px ({len(corners_spaced)} pts)', fontsize=12)
ax2.axis('off')

plt.tight_layout()
plt.savefig('/Users/yeonge/SynologyDrive/1. YeongE/7. Visual SLAM Study/visual-slam-learning/Studies/Phase 2/week3/uniform_distribution.png', dpi=150)
print("Uniform distribution saved: uniform_distribution.png")

# ============================================================
# ë¬¸ì œ 5: ì•Œê³ ë¦¬ì¦˜ ë¹„êµ
# ============================================================
print("\n" + "=" * 70)
print("ë¬¸ì œ 5: ì•Œê³ ë¦¬ì¦˜ ì†ë„ ë¹„êµ")
print("=" * 70)

print("""
ğŸ¯ ëª©í‘œ: Harris vs FAST ì†ë„ ë¹„êµ

FASTê°€ ë¹ ë¥¸ ì´ìœ :
1. ê°„ë‹¨í•œ ë¹„êµ ì—°ì‚°ë§Œ ì‚¬ìš©
2. Early exit (4ì  í…ŒìŠ¤íŠ¸ë¡œ ë¹ ë¥´ê²Œ ì œì™¸)
3. í–‰ë ¬ ì—°ì‚° ì—†ìŒ
""")

import time

# ì†ë„ í…ŒìŠ¤íŠ¸
test_sizes = [100, 200, 300]
harris_times = []
simple_times = []

print("\nì´ë¯¸ì§€ í¬ê¸°ë³„ ì²˜ë¦¬ ì‹œê°„:")
print("-" * 50)
print(f"{'Size':>10} | {'Harris (ms)':>15} | {'Simple (ms)':>15}")
print("-" * 50)

for size in test_sizes:
    img = create_test_image_with_noise(size, 0)
    
    # Harris
    start = time.time()
    for _ in range(10):
        R = harris_corner_detector(img)
    harris_time = (time.time() - start) / 10 * 1000
    harris_times.append(harris_time)
    
    # Simple comparison (simulating FAST concept)
    start = time.time()
    for _ in range(10):
        # ê°„ë‹¨í•œ ë¹„êµ ì—°ì‚° ì‹œë®¬ë ˆì´ì…˜
        diff = np.abs(img[:-2, 1:-1] - img[2:, 1:-1])
    simple_time = (time.time() - start) / 10 * 1000
    simple_times.append(simple_time)
    
    print(f"{size:>10} | {harris_time:>15.2f} | {simple_time:>15.2f}")

print("\nğŸ’¡ ì‹¤ì œ OpenCV FASTëŠ” ì´ë³´ë‹¤ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤!")

# ============================================================
# ì •ë¦¬
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“š Week 3 Quiz ì •ë¦¬")
print("=" * 70)

print("""
âœ… ë¬¸ì œ 1: NMS
   - ì§€ì—­ ìµœëŒ€ê°’ë§Œ ìœ ì§€
   - ì¤‘ë³µ ê²€ì¶œ ì œê±°
   
âœ… ë¬¸ì œ 2: íŒŒë¼ë¯¸í„° íŠœë‹
   - threshold â†‘ â†’ ì ì€ ê²€ì¶œ, ê°•í•œ ì½”ë„ˆ
   - threshold â†“ â†’ ë§ì€ ê²€ì¶œ, ì•½í•œ ì½”ë„ˆë„
   
âœ… ë¬¸ì œ 3: ë…¸ì´ì¦ˆ ê°•ê±´ì„±
   - ë…¸ì´ì¦ˆ â†‘ â†’ ê±°ì§“ ê²€ì¶œ â†‘
   - ì „ì²˜ë¦¬(ê°€ìš°ì‹œì•ˆ) ë„ì›€
   
âœ… ë¬¸ì œ 4: ê· ì¼ ë¶„í¬
   - ìµœì†Œ ê±°ë¦¬ ì œì•½ (min_dist)
   - VINS: 30 í”½ì…€
   
âœ… ë¬¸ì œ 5: ì†ë„ ë¹„êµ
   - FAST >> Harris
   - ì‹¤ì‹œê°„ SLAM = FAST

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’¡ SLAM íŒŒë¼ë¯¸í„° ê°€ì´ë“œ:

| ìƒí™© | threshold | min_dist | max_features |
|------|-----------|----------|--------------|
| í…ìŠ¤ì²˜ í’ë¶€ | ë†’ì„ | ë„“í˜ | ì¤„ì„ |
| í…ìŠ¤ì²˜ ë¶€ì¡± | ë‚®ì¶¤ | ì¢í˜ | ëŠ˜ë¦¼ |
| ë¹ ë¥¸ ì›€ì§ì„ | ë‚®ì¶¤ | - | ëŠ˜ë¦¼ |
| ëŠë¦° ì›€ì§ì„ | ë†’ì„ | - | ì¤„ì„ |

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ ë‹¤ìŒ: Week 4 - íŠ¹ì§•ì  ë§¤ì¹­ (Brute-Force, FLANN, RANSAC)
""")

print("\n" + "=" * 70)
print("feature_detection_quiz.py ì‹¤í–‰ ì™„ë£Œ! ğŸ‰")
print("=" * 70)
print("\nìƒì„±ëœ íŒŒì¼:")
print("  1. feature_detection_comparison.png - Harris/FAST ë¹„êµ")
print("  2. nms_comparison.png - NMS ì „í›„")
print("  3. threshold_tuning.png - íŒŒë¼ë¯¸í„° íš¨ê³¼")
print("  4. noise_robustness.png - ë…¸ì´ì¦ˆ ê°•ê±´ì„±")
print("  5. uniform_distribution.png - ê· ì¼ ë¶„í¬")
